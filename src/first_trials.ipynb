{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM loaded\n",
      "Loading corpus and search results...\n",
      "Corpus and search results loaded\n",
      "Loading prompt dataset...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "PromptDataset.__init__() got an unexpected keyword argument 'get_documents_without_answer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 209\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    208\u001b[0m     seed_everything(SEED)\n\u001b[1;32m--> 209\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 197\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorpus and search results loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading prompt dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 197\u001b[0m prompt_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_dataset_and_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_to_subset_idx_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt dataset loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    202\u001b[0m print_info(args)\n",
      "Cell \u001b[1;32mIn[14], line 90\u001b[0m, in \u001b[0;36minitialize_dataset_and_loader\u001b[1;34m(args, corpus, full_to_subset_idx_map, search_results, tokenizer)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize_dataset_and_loader\u001b[39m(\n\u001b[0;32m     83\u001b[0m     args: argparse\u001b[38;5;241m.\u001b[39mNamespace, \n\u001b[0;32m     84\u001b[0m     corpus: List[Dict], \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m     tokenizer: PreTrainedTokenizer\n\u001b[0;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataLoader:\n\u001b[1;32m---> 90\u001b[0m     prompt_ds \u001b[38;5;241m=\u001b[39m \u001b[43mPromptDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokenized_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_max_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_to_subset_idx_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_to_subset_idx_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_normalize_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_documents_in_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_documents_in_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgold_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgold_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_documents_without_answer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_documents_without_answer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m     prompt_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m    102\u001b[0m         prompt_ds,\n\u001b[0;32m    103\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m         pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    107\u001b[0m     )\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prompt_dataloader\n",
      "\u001b[1;31mTypeError\u001b[0m: PromptDataset.__init__() got an unexpected keyword argument 'get_documents_without_answer'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import argparse\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, Dict, Optional\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "from llm import LLM\n",
    "from utils import *\n",
    "from prompt_dataset import PromptDataset\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "device = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED=10\n",
    "\n",
    "info = {\n",
    "    \"data_path\": r\"C:\\Users\\franc\\Documents\\Bridge_the_GAP\\data\\test_dataset.json\",\n",
    "    \"contriever_search_results_path\": r\"C:\\Users\\franc\\Documents\\Bridge_the_GAP\\data\\processed\\contriever_test_search_results_at150.pkl\",\n",
    "}\n",
    "\n",
    "class DotDict:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "def parse_arguments(custom_args=None):\n",
    "    \"\"\"\n",
    "    Mimics argparse to parse arguments for LLM generation. Accepts custom arguments as a dictionary for notebooks.\n",
    "    \"\"\"\n",
    "    # Define default values\n",
    "    default_args = {\n",
    "        'output_dir': r'C:\\Users\\franc\\Documents\\Bridge_the_GAP\\data\\gen_res_example_llm',\n",
    "        'llm_id': 'google/gemma-2-2b-it',\n",
    "        'model_max_length': 4096,\n",
    "        'gold_position': None,\n",
    "        'num_documents_in_context': None,\n",
    "        'get_documents_without_answer': True,\n",
    "        'max_new_tokens': 50,\n",
    "        'batch_size': None,\n",
    "        'save_every': 250,\n",
    "    }\n",
    "\n",
    "    # If custom_args is provided, update defaults\n",
    "    if custom_args:\n",
    "        default_args.update(custom_args)\n",
    "\n",
    "    # Perform validation\n",
    "    if default_args['num_documents_in_context'] is None:\n",
    "        raise ValueError(\"'num_documents_in_context' must be specified.\")\n",
    "    if default_args['num_documents_in_context'] <= 0:\n",
    "        raise ValueError(\"'num_documents_in_context' must be a positive integer.\")\n",
    "    if default_args['gold_position'] is not None:\n",
    "        if (default_args['gold_position'] < 0 or \n",
    "            default_args['gold_position'] >= default_args['num_documents_in_context']):\n",
    "            raise ValueError(\"'gold_position' must be within the range of 'num_documents_in_context'.\")\n",
    "\n",
    "    return DotDict(**default_args)\n",
    "\n",
    "\n",
    "def load_corpus(\n",
    "    args: argparse.Namespace\n",
    ") -> Tuple[List[Dict], Optional[Dict[int, int]]]:\n",
    "    \n",
    "    # Corpus with documents from Contriever\n",
    "    corpus, full_to_subset_idx_map = read_test_corpus_with_random_and_contriever()\n",
    "\n",
    "    return corpus, full_to_subset_idx_map\n",
    "\n",
    "\n",
    "def load_search_results(args: argparse.Namespace) -> List[Tuple[List[int], List[float]]]:\n",
    "    # Search results from Contriever\n",
    "    search_results_path = info['contriever_search_results_path'] \n",
    "\n",
    "    search_results = read_pickle(search_results_path)\n",
    "    return search_results\n",
    "\n",
    "\n",
    "def initialize_dataset_and_loader(\n",
    "    args: argparse.Namespace, \n",
    "    corpus: List[Dict], \n",
    "    full_to_subset_idx_map: Optional[Dict[int, int]], \n",
    "    search_results: List[Tuple[List[int], List[float]]], \n",
    "    tokenizer: PreTrainedTokenizer\n",
    ") -> DataLoader:\n",
    "    \n",
    "    prompt_ds = PromptDataset(\n",
    "        corpus=corpus, data_path=info['data_path'], \n",
    "        tokenizer=tokenizer, \n",
    "        max_tokenized_length=args.model_max_length - 2, \n",
    "        search_results=search_results,\n",
    "        full_to_subset_idx_map=full_to_subset_idx_map,\n",
    "        do_normalize_query=True, \n",
    "        num_documents_in_context=args.num_documents_in_context,\n",
    "        gold_position=args.gold_position,\n",
    "        get_documents_without_answer=args.get_documents_without_answer,\n",
    "    )\n",
    "    prompt_dataloader = DataLoader(\n",
    "        prompt_ds,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return prompt_dataloader\n",
    "\n",
    "\n",
    "def print_info(args: argparse.Namespace):\n",
    "    print(\"INFO:\")\n",
    "    print(f\"DATA: {info['data_path']}\")\n",
    "    print(f\"MODEL: {args.llm_id}\")\n",
    "    print(f\"GOLD POSITION: {args.gold_position}\")\n",
    "    print(f\"NUM DOCUMENTS IN CONTEXT: {args.num_documents_in_context}\")\n",
    "    print(f\"DOCUMENTS WITHOUT ANSWER: {args.get_documents_without_answer}\")\n",
    "    print(f\"MAX NEW TOKENS: {args.max_new_tokens}\")\n",
    "    print(f\"BATCH SIZE: {args.batch_size}\")\n",
    "    print(f\"SAVE EVERY: {args.save_every}\")\n",
    "\n",
    "\n",
    "def generate_and_save(\n",
    "    args: argparse.Namespace, \n",
    "    llm: LLM, \n",
    "    prompt_dataloader: DataLoader\n",
    "):\n",
    "    # Info from arguments\n",
    "    llm_id = args.llm_id\n",
    "    num_doc = args.num_documents_in_context\n",
    "    save_every = args.save_every\n",
    "    gold_pos = args.gold_position\n",
    "    retriever_str = \"contriever\"\n",
    "    answerless_str = \"_answerless\" if args.get_documents_without_answer else \"\"\n",
    "\n",
    "    # Create the saving directory\n",
    "    llm_folder = llm_id.split(\"/\")[1] if '/' in llm_id else llm_id\n",
    "    saving_dir = f\"{args.output_dir}/{llm_folder}/test/classic/{retriever_str}/{num_doc}_doc\"\n",
    "    if not os.path.exists(saving_dir):\n",
    "        os.makedirs(saving_dir)\n",
    "\n",
    "    \n",
    "    # MPT has a different answer string in the prompt\n",
    "    answer_string_in_prompt = \"### Response:\" if 'mpt' in llm_id else \"Answer:\"\n",
    "\n",
    "    all_info = []  \n",
    "    for idx, prompt_batch in enumerate(tqdm(prompt_dataloader)):\n",
    "        prompts = prompt_batch['prompt']\n",
    "        generated_output = llm.generate(prompts, max_new_tokens=args.max_new_tokens)\n",
    "        \n",
    "        generated_answers = []\n",
    "        for output in generated_output:\n",
    "            start = output.find(answer_string_in_prompt) + len(answer_string_in_prompt)\n",
    "            response = output[start:].strip()\n",
    "            generated_answers.append(response)\n",
    "\n",
    "        prompt_batch['generated_answer'] = generated_answers\n",
    "        all_info.append(prompt_batch)\n",
    "        \n",
    "        if (idx + 1) % save_every == 0 or (idx + 1) == len(prompt_dataloader):\n",
    "            print(f\"Saving at {idx + 1}...\")\n",
    "            file_name = f\"{saving_dir}/numdoc{num_doc}_gold_at{gold_pos}{answerless_str}_info_{idx+1}.pkl\"\n",
    "            write_pickle(all_info, file_name)\n",
    "            all_info = []\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parse_arguments({\n",
    "        'output_dir': r'C:\\Users\\franc\\Documents\\Bridge_the_GAP\\data\\gen_res_example_llm',\n",
    "        'llm_id': 'google/gemma-2-2b-it',\n",
    "        'model_max_length': 4096,\n",
    "        'gold_position': None,\n",
    "        'num_documents_in_context': 5,\n",
    "        'get_documents_without_answer': True,\n",
    "        'max_new_tokens': 50,\n",
    "        'batch_size': None,\n",
    "        'save_every': 250,\n",
    "    })\n",
    "\n",
    "    print(\"Loading LLM...\")\n",
    "    llm_id = args.llm_id\n",
    "    llm = LLM(\n",
    "        llm_id, device, quantization_bits=4, \n",
    "        model_max_length=args.model_max_length\n",
    "    )\n",
    "    tokenizer = llm.tokenizer\n",
    "    print(\"LLM loaded\")\n",
    "\n",
    "\n",
    "    print(\"Loading corpus and search results...\")\n",
    "    corpus, full_to_subset_idx_map = load_corpus(args)\n",
    "    search_results = load_search_results(args)\n",
    "    print(\"Corpus and search results loaded\")\n",
    "\n",
    "\n",
    "    print(\"Loading prompt dataset...\")\n",
    "    prompt_dataloader = initialize_dataset_and_loader(\n",
    "        args, corpus, full_to_subset_idx_map, search_results, tokenizer\n",
    "    )\n",
    "    print(\"Prompt dataset loaded\")\n",
    "\n",
    "    print_info(args)\n",
    "    generate_and_save(args, llm, prompt_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    seed_everything(SEED)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results of generate_answer_llm\n",
    "from utils import *\n",
    "\n",
    "result_path=r\"C:\\Users\\franc\\Documents\\Bridge_the_GAP\\data\\gen_res_example_llm\\gemma-2-2b-it\\test\\classic\\contriever\\5_doc\\numdoc5_gold_atNone_answerless_info_250.pkl\"\n",
    "data=read_pickle(result_path)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM loaded\n",
      "Loading corpus and search results...\n",
      "Corpus and search results loaded\n",
      "Loading prompt dataset...\n",
      "Prompt dataset loaded\n",
      "INFO:\n",
      "DATA: C:\\Users\\franc\\Documents\\Bridge_the_GAP\\data\\test_dataset.json\n",
      "USE TEST: True\n",
      "MODEL: google/gemma-2-2b-it\n",
      "MODEL MAX LENGTH: 4096\n",
      "MAX NEW TOKENS: 50\n",
      "USE MODEL CHAT TEMPLATE: True\n",
      "TASK WITH PROOF: False\n",
      "GOLD POSITION: None\n",
      "NUM DOCUMENTS IN CONTEXT: 5\n",
      "BATCH SIZE: None\n",
      "SAVE EVERY: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2889 [01:04<51:54:01, 64.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Prefix: Answer:\\nmodel\n",
      "Generated Output: ['user\\nYou are given a question and you must respond based on the provided documents. You must always provide an answer.\\nDocuments:\\nDocument [628506](Title: Nobel Prize in Physics) receive a diploma, a medal and a document confirming the prize amount. Nobel Prize in Physics The Nobel Prize in Physics () is a yearly award given by the Royal Swedish Academy of Sciences for those who have made the most outstanding contributions for mankind in the field of physics. It is one of the five Nobel Prizes established by the will of Alfred Nobel in 1895 and awarded since 1901; the others being the Nobel Prize in Chemistry, Nobel Prize in Literature, Nobel Peace Prize, and Nobel Prize in Physiology or Medicine. The first Nobel Prize in Physics was\\nDocument [3546609](Title: E. C. George Sudarshan) had developed the breakthrough. In 2007, Sudarshan told the \"Hindustan Times\", \"The 2005 Nobel prize for Physics was awarded for my work, but I wasn\\'t the one to get it. Each one of the discoveries that this Nobel was given for work based on my research.\" Sudarshan also commented on not being selected for the 1979 Nobel, \"Steven Weinberg, Sheldon Glashow and Abdus Salam built on work I had done as a 26-year-old student. If you give a prize for a building, shouldn’t the fellow who built the first floor be given the prize before those who built the second\\nDocument [439756](Title: University of Chicago) Medal, which is rewarded annually to the best economist under the age of 40, has also been awarded to 4 current members of the university faculty. Notable faculty in physics have included the speed of light calculator A. A. Michelson, elementary charge calculator Robert A. Millikan, discoverer of the Compton Effect Arthur H. Compton, the creator of the first nuclear reactor Enrico Fermi, \"the father of the hydrogen bomb\" Edward Teller, \"one of the most brilliant and productive experimental physicists of the twentieth century\" Luis Walter Alvarez, Murray Gell-Mann who introduced the quark, second female Nobel laureate Maria Goeppert-Mayer, the\\nDocument [1860765](Title: Tsung-Dao Lee) 1956, with her so-called Wu experiment. Lee was the youngest Nobel laureate after World War II until Malala Yousafzai was awarded the Nobel Peace Prize in 2014. He is the fourth youngest Nobel laureate in history after William L. Bragg (who won the prize at 25 with his father William H. Bragg in 1915), Werner Heisenberg (who won in 1932 also at 30) and Malala Yousafzai (awarded at just 17). Lee and Yang were the first Chinese laureates. Since he became a naturalized American citizen in 1962, Lee is also the youngest American ever to have won a Nobel Prize.\\nDocument [2043329](Title: Universology) become the chief proponent of universology today. \"Everything in this universe is part of an uninterrupted sequence of events\" Mohri has said. In 1872 Andrews published \"The Basic Outline of Universology\" which was subtitled \"An introduction to the newly discovered science of the universe, its elementary principles, and the first stages of their development in the special sciences.\" Ilya Romanovich Prigogine (born on January 25, 1917) was a Belgian and American physicist and chemist who was born in Russia and became a Nobel Prize laureate in chemistry. In the book \"Order Out of Chaos: Man\\'s New Dialogue With Nature\", which\\nQuestion: who got the first nobel prize in physics\\nAnswer:\\nmodelAnswer:  The provided text does not state who received the first Nobel Prize in Physics. \\n']\n",
      "Have you find matches?: [<re.Match object; span=(3379, 3392), match='Answer:\\nmodel'>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2889 [01:06<22:18:29, 27.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Prefix: Answer:\\nmodel\n",
      "Generated Output: ['user\\nYou are given a question and you must respond based on the provided documents. You must always provide an answer.\\nDocuments:\\nDocument [3201523](Title: Cable & Deadpool) the symbiote. However, Deadpool stabs himself in the head with the psimitar, and is released from the grip of the symbiote. Deadpool awakes to find out from the Avengers that the dinosaurs have been returned to the jungle thanks to Weasel. It all ends with Deadpool back at his apartment watching TV. Deadpool had been blamed for the incident by the media on TV. Weasel, Bob, Irene Merryweather, Agent X, Sandi, and Outlaw all come in to hang out with Deadpool. The series ends with Deadpool asking his friends, \"So... whaddyou guys want to watch?\" Cable & Deadpool Cable &\\nDocument [3246420](Title: X-Force) gray area. It\\'ll be raunchier, it\\'ll be rated R, I\\'m sure. We\\'ll get to see an ensemble movie that\\'s pushed, hopefully, as far as the Deadpool individual movie was pushed.\" The team (consisting of Domino, Fantomex and Archangel) appear in Deadpool\\'s ending in \"Ultimate Marvel vs. Capcom 3\". They are shown celebrating Deadpool\\'s victory over Galactus alongside Cable, Bob, Agent of HYDRA and several Capcom characters. In April 2010, the popular Web comic Homestar Runner featured a parody titled \"Xeriouxly Forxe\", in which all of the site\\'s main characters except Homsar were re-designed to look like X-Men. X-Force X-Force is\\nDocument [10435180](Title: X-Men (film series)) marked both Hugh Jackman and Patrick Stewart\\'s return as Wolverine and Xavier, respectively. After a personal tragedy, Deadpool creates the X-Force to save a young mutant from the time-traveling soldier Cable. In September 2015, Kinberg said that a sequel for \"Deadpool\" was in development. By the release of \"Deadpool\", 20th Century Fox greenlit the film, with Rheese and Wernick returning to write, and Miller being looked at to return as director, as he was working on the script at the time. However in October 2016, Miller left the film due to creative differences with Reynolds and was replaced by David\\nDocument [3201509](Title: Cable & Deadpool) Deadpool, with Weasel, goes to the Hydra Headquarters where Agent X is being held, in Pakistan. Using his small size to his advantage, Deadpool infiltrates the Headquarters and captures Bob, Agent of HYDRA, to help him get to Agent X. It is then found that the actuator has been used to give Agent X morbid obesity by scientists experimenting with the actuator, and that it can not be removed by the actuator. Deadpool then forces the scientists to turn him back to his normal size (\"They had some Pym Particles lying around. Figured they must. Who doesn\\'t, right?\") and gets\\nDocument [3180056](Title: Rob Liefeld) on the graphic novel \"Deadpool: Bad Blood\", which is set for release later that year. In 2017, it was reported by Deadline that Liefeld is working with Akiva Goldsman and Graham King on a seven-figure movie deal for his Extreme Universe. Liefeld\\'s name has become something of a lightning rod in the industry. In an interview, Brian Michael Bendis described the polarization of opinion on Liefeld: \"There is a great dichotomy...There\\'s either some great and generous story about [Liefeld] or you will hear some unbelievable thing like, \\'How is he not in jail if he did that?\\' There is no\\nQuestion: when is the next deadpool movie being released\\nAnswer:\\nmodelThe provided text does not contain information about the release date of the next Deadpool movie. \\n']\n",
      "Have you find matches?: [<re.Match object; span=(3375, 3388), match='Answer:\\nmodel'>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2889 [01:11<13:49:19, 17.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Prefix: Answer:\\nmodel\n",
      "Generated Output: ['user\\nYou are given a question and you must respond based on the provided documents. You must always provide an answer.\\nDocuments:\\nDocument [283714](Title: Geography of Nigeria) finally retreats from most part of Nigeria, and the West African atmosphere around April to May, leaving an empty atmosphere over Nigeria. The sun\\'s rays enters into the atmosphere of Nigeria more intense than it does during the presence of the Tropical continental airmass, which contained dust (in form of haze) that reduced the intensity of the sun. The overheating of the west Africa land mass and Nigeria in particular creates a low pressure region over west Africa and Nigeria. This low pressure zone attracts the Tropical Maritime Airmass (MT) from the south Atlantic Ocean since areas of low pressures\\nDocument [283712](Title: Geography of Nigeria) of low pressure to develop over west Africa and Nigeria (between March to May). The Tropical continental airmass (CT) from the Sahara Desert in the northern part of West Africa, is weakened due to the overheating of the land surface in west Africa and Nigeria at this time. The Tropical continental airmass (CT) begins to retreat northwards to the Sahara Desert due to massive heating of the land which transfers heat in the form of convection into the Tropical continental airmass (CT) which constitutes the main layer of air above the land. This transfer of heat in the Tropical continental\\nDocument [283711](Title: Geography of Nigeria) West Africa comes directly under the sun at this time. The sun is overhead throughout west Africa and over Nigeria during this period of the sun\\'s northward migration to the tropic of cancer in the northern hemisphere. The whole of West Africa is heated intensely as result of the increased insolation received from the sun being overhead over west Africa. Temperatures can climb as high as over west Africa during this time. Temperatures in the northern part of Nigeria can go as high as in cities like Maiduguri. The high temperatures coupled with an increase in insolation causes a region\\nDocument [283717](Title: Geography of Nigeria) northern end is south of the 15 degrees line at about 14 degrees. Nigeria\\'s location in the wetter part of the easterly waves south of the 15 degree line creates wetter climatic conditions for Nigeria especially during the monsoons. The Tropical Continental Airmass (CT) locally known as the harmattan, is a wind originating from North Africa which crosses the Sahara Desert into west Africa to Nigeria. This airmass dominates Nigeria\\'s climate during the dry season from December to March. The Tropical continental airmass is dusty and creates a haze within the atmosphere of west Africa and Nigeria when it predominates.\\nDocument [283713](Title: Geography of Nigeria) airmass (CT) in turn, causes the wind to expand and become lighter as this is the normal behaviour for winds moving above intensely heated grounds. The Tropical continental airmass (CT) loses its strength as a major airmass in the region of west Africa and over Nigeria at this time (around February in the southern part of Nigeria to June in northern Nigeria) and begins to retreat coupled with the rising of air in form of convection within this airmass (Tropical continental airmass (CT)), further weakening the dominance of the wind over west Africa and Nigeria. The Tropical continental airmass (CT)\\nQuestion: the south west wind blows across nigeria between\\nAnswer:\\nmodelThe provided text doesn\\'t explicitly state the exact timing or frequency of the south-west wind blowing across Nigeria.  \\n\\nHowever, we can infer some information:\\n\\n* **Harmattan:** The document describes the \"Tropical Continental Airmass\"']\n",
      "Have you find matches?: [<re.Match object; span=(3447, 3460), match='Answer:\\nmodel'>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2889 [01:15<9:49:10, 12.25s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Prefix: Answer:\\nmodel\n",
      "Generated Output: ['user\\nYou are given a question and you must respond based on the provided documents. You must always provide an answer.\\nDocuments:\\nDocument [2979957](Title: Revolution in Military Affairs) transformed warfare, and, as a result, the question is not one of \"Does an RMA exist?\" but, rather, \"When did it begin, and what are its implications?\" Tied to this are surprisingly persistent questions about the use and value of air power, now more accurately seen as aerospace power. If nothing else, given the record of precision air power application, aerospace power advocates should not still have to spend as much time as they do arguing the merits of three-dimensional war and precision attack\\'s value to it. Modern joint service aerospace forces offer the most responsive, flexible, lethal, and devastating\\nDocument [3526617](Title: Navy Marine Corps Intranet) perspective, produced results that were far from optimal.” NMCI consolidated roughly 6,000 networks—some of which could not e-mail, let alone collaborate with each other—into a single integrated and secure IT environment. HP updated more than 100,000 desktop and laptop PCs in 2007. The program also consolidated an ad hoc network of more than 8,000 applications to 500 in four years and 15,003 logistics and readiness systems to 2,759 over a two-year period. Sub-contractors to HP include: HP also provides the security services once provided by Raytheon. HP also has worked with more than 400 small businesses, with 5 percent for\\nDocument [12643438](Title: A World At War) dropping. Kamikazes no longer defend against enemy aircraft; they are no longer doubled to attack ships, but instead attack with +4 DRM. Kamikazes pick targets at random (carriers, then battleships, in order of size and slowness, then light ships as a group, damaged ships first in every category) in the same way as submarines; they combine their attack if more than one selects the same target. Jets - only available after a high research result - fight at triple strength and have a +1 modifier in combat. For activities at sea each Army Air Factor splits into search, cover and\\nDocument [11673357](Title: HP 35s) and make decisions. All programs are stored in one continuous program space, and may be created and edited by switching to programming mode, using the key. Within the program space, up to twenty-six alphabetic labels may be defined in the form , and each label may be followed by up to 998 other steps, so that any step may be targeted by a (\"go to\") or (\"execute\") instruction in the form (or just for the label step itself, A001). Any steps before the first label are numbered with four digits, but these steps cannot be targeted. Subsequent insertion or deletion\\nDocument [12638363](Title: War and Peace (game)) Spain and Russia where it was harder for armies to live off the land; all units in their home country get a -1 DRM whereas unsupplied units get a +1 DRM). If more than one strength point is to be lost then one of them must be cavalry if there is one in the hex. Neutral countries are immune from attrition, enabling a defeated major power to rebuild their forces until they rejoin the war. Diplomacy takes place in the alliance phase. This system is used to allow nations to ally with one another. Alliances essentially allow you to acquire\\nQuestion: what does hp mean in war and order\\nAnswer:\\nmodelBased on the provided documents, HP likely stands for **Hewlett-Packard**. \\n\\nThe document mentions HP providing security services, updating computers, and working with small businesses.  This aligns with Hewlett-Packard\\'s well-known history as a']\n",
      "Have you find matches?: [<re.Match object; span=(3351, 3364), match='Answer:\\nmodel'>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2889 [01:18<7:08:11,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Prefix: Answer:\\nmodel\n",
      "Generated Output: ['user\\nYou are given a question and you must respond based on the provided documents. You must always provide an answer.\\nDocuments:\\nDocument [3932834](Title: Human Rights Day) and societies should \"strive by progressive measures, national and international, to secure their universal and effective recognition and observance\". The measure was received by both advocates and critics alike as \"being more declarative than legislative, more suggestive than binding.\" Although the Declaration with its broad range of political, civil, economic, social and cultural rights is not a binding document, it inspired more than 60 human rights instruments which together constitute an international standard of human rights. Today the general consent of all United Nations Member States on the basic Human Rights laid down in the Declaration makes it even stronger\\nDocument [182208](Title: Human rights) and peace in the world.\" The declaration was the first international legal effort to limit the behaviour of states and press upon them duties to their citizens. The UDHR was framed by members of the Human Rights Commission, with former First Lady Eleanor Roosevelt as Chair, who began to discuss an \"International Bill of Rights\" in 1947. The members of the Commission did not immediately agree on the form of such a bill of rights, and whether, or how, it should be enforced. The Commission proceeded to frame the UDHR and accompanying treaties, but the UDHR quickly became the priority.\\nDocument [13616094](Title: Human rights in the United States) prisoners at Guantanamo Bay and black sites, and extrajudicial targeted killings (Disposition Matrix). Some observers give the U.S. high to fair marks on human rights, while others charge it with a persistent pattern of human rights violations. The first human rights organization in the Thirteen Colonies of British America, dedicated to the abolition of slavery, was formed by Anthony Benezet in 1775. A year later, the Declaration of Independence announced that the Thirteen Colonies regarded themselves as independent states, and no longer a part of the British Empire. The Declaration stated \"that all men are created equal, that they are\\nDocument [781100](Title: Bartolomé de las Casas) In the Catholic Church, the Dominicans introduced his cause for canonization in 1976. In 2002 the Church began the process for his beatification. He has also come to be seen as an early advocate for a concept of universal human rights. He was among the first to develop a view of unity among humankind, stating that \"All people of the world are humans,\" and that they had a natural right to liberty – a combination of Thomist rights philosophy with Augustinian political theology. In this capacity, an ecumenical human rights institute located in San Cristóbal de las Casas, the Centro\\nDocument [434619](Title: Universal Declaration of Human Rights) the Rights of the Child, the United Nations Convention Against Torture, and many more. The Declaration continues to be widely cited by governments, academics, advocates, and constitutional courts, and by individuals who appeal to its principles for the protection of their recognised human rights. The Universal Declaration has received praise from a number of notable people. The Lebanese philosopher and diplomat Charles Malik called it \"an international document of the first order of importance\", while Eleanor Roosevelt—first chairwoman of the Commission on Human Rights (CHR) that drafted the Declaration—stated that it \"may well become the international Magna Carta of all\\nQuestion: who wrote the first declaration of human rights\\nAnswer:\\nmodelThe first international legal effort to limit the behavior of states and press upon them duties to their citizens was the **Universal Declaration of Human Rights**. \\n']\n",
      "Have you find matches?: [<re.Match object; span=(3624, 3637), match='Answer:\\nmodel'>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2889 [01:24<13:35:39, 16.97s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 269\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    268\u001b[0m     seed_everything(SEED)\n\u001b[1;32m--> 269\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 263\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt dataset loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    262\u001b[0m print_info(args)\n\u001b[1;32m--> 263\u001b[0m \u001b[43mgenerate_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 218\u001b[0m, in \u001b[0;36mgenerate_and_save\u001b[1;34m(args, llm, prompt_dataloader)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, prompt_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(prompt_dataloader)):\n\u001b[0;32m    217\u001b[0m     prompts \u001b[38;5;241m=\u001b[39m prompt_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 218\u001b[0m     generated_output \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m     generated_answers \u001b[38;5;241m=\u001b[39m extract_generate_answers(args, generated_output)\n\u001b[0;32m    225\u001b[0m     prompt_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_answer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m generated_answers\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\src\\llm.py:121\u001b[0m, in \u001b[0;36mLLM.generate\u001b[1;34m(self, prompt, padding_strategy, max_new_tokens)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03mGenerates text based on the given prompt.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03m    List[str]: The generated text responses.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    113\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\n\u001b[0;32m    114\u001b[0m     prompt, \n\u001b[0;32m    115\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding_strategy, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 121\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(generated_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\transformers\\generation\\utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2212\u001b[0m     )\n\u001b[0;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2235\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\transformers\\generation\\utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   3210\u001b[0m     outputs,\n\u001b[0;32m   3211\u001b[0m     model_kwargs,\n\u001b[0;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   3213\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\accelerate\\hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\transformers\\models\\gemma2\\modeling_gemma2.py:1049\u001b[0m, in \u001b[0;36mGemma2ForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[0;32m   1047\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1049\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\accelerate\\hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\transformers\\models\\gemma2\\modeling_gemma2.py:837\u001b[0m, in \u001b[0;36mGemma2Model.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    826\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    827\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    828\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    834\u001b[0m         cache_position,\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 837\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    847\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\accelerate\\hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\transformers\\models\\gemma2\\modeling_gemma2.py:553\u001b[0m, in \u001b[0;36mGemma2DecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[0;32m    550\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[0;32m    552\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m--> 553\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m    563\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\accelerate\\hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\transformers\\models\\gemma2\\modeling_gemma2.py:268\u001b[0m, in \u001b[0;36mGemma2Attention.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[0;32m    265\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    267\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 268\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[0;32m    271\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\accelerate\\hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[1;34m(module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\bitsandbytes\\nn\\modules.py:484\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    481\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[0;32m    483\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[1;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mto(inp_dtype)\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:574\u001b[0m, in \u001b[0;36mmatmul_4bit\u001b[1;34m(A, B, quant_state, out, bias)\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MatMul4Bit\u001b[38;5;241m.\u001b[39mapply(A, B, out, bias, quant_state)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 574\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgemv_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    576\u001b[0m         out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m bias\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\bitsandbytes\\functional.py:2025\u001b[0m, in \u001b[0;36mgemv_4bit\u001b[1;34m(A, B, out, transposed_A, transposed_B, state)\u001b[0m\n\u001b[0;32m   2023\u001b[0m absmax \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mabsmax\n\u001b[0;32m   2024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mnested:\n\u001b[1;32m-> 2025\u001b[0m     absmax \u001b[38;5;241m=\u001b[39m \u001b[43mdequantize_blockwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabsmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2026\u001b[0m     absmax \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39moffset\n\u001b[0;32m   2028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\franc\\Documents\\Bridge_the_GAP\\myenv\\Lib\\site-packages\\bitsandbytes\\functional.py:997\u001b[0m, in \u001b[0;36mdequantize_blockwise\u001b[1;34m(A, quant_state, absmax, code, out, blocksize, nested)\u001b[0m\n\u001b[0;32m    995\u001b[0m stream \u001b[38;5;241m=\u001b[39m get_tensor_stream(A)\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[1;32m--> 997\u001b[0m     \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcdequantize_blockwise_fp32\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquant_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabsmax\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquant_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Used the _as_parameter_ attribute of torch.cuda.Stream, Similarly for the following\u001b[39;49;00m\n\u001b[0;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n\u001b[0;32m   1007\u001b[0m     lib\u001b[38;5;241m.\u001b[39mcdequantize_blockwise_fp16(\n\u001b[0;32m   1008\u001b[0m         get_ptr(quant_state\u001b[38;5;241m.\u001b[39mcode),\n\u001b[0;32m   1009\u001b[0m         get_ptr(A),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1014\u001b[0m         stream,\n\u001b[0;32m   1015\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re \n",
    "import argparse\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, Dict, Optional\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "from utils import *\n",
    "from llm import LLM\n",
    "from default_prompts import *\n",
    "from prompt_dataset import PromptDataset\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "device = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED=10\n",
    "\n",
    "info = {\n",
    "    \"nq\": {\n",
    "        \"test\": {\n",
    "            \"data_path\": r'C:\\Users\\franc\\Documents\\Bridge_the_GAP\\data\\test_dataset.json',\n",
    "            \"contriever_search_results_path\": r\"C:\\Users\\franc\\Documents\\Bridge_the_GAP\\data\\processed\\contriever_test_search_results_at150.pkl\",\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "class DotDict:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "def parse_arguments(custom_args=None):\n",
    "    \"\"\"\n",
    "    Mimics argparse to parse arguments for LLM generation. Accepts custom arguments as a dictionary for notebooks.\n",
    "    \"\"\"\n",
    "    # Define default values\n",
    "    default_args = {\n",
    "        'output_dir': r'C:\\Users\\franc\\Documents\\Bridge_the_GAP\\data\\gen_res_example_llm',\n",
    "        'llm_id': 'google/gemma-2-2b-it',\n",
    "        'dataset': 'nq',\n",
    "        'model_max_length': 4096,\n",
    "        'quantization_bits': 4,\n",
    "        'use_model_chat_template': True, \n",
    "        'gold_position': None,\n",
    "        'num_retrieved_documents': 5,\n",
    "        'use_test': True,\n",
    "        'padding_strategy': 'longest',\n",
    "        'max_new_tokens': 50,\n",
    "        'use_task_with_proof': False,\n",
    "        'batch_size': None,\n",
    "        'save_every': 250,\n",
    "    }\n",
    "\n",
    "    # If custom_args is provided, update defaults\n",
    "    if custom_args:\n",
    "        default_args.update(custom_args)\n",
    "\n",
    "    # Perform validation\n",
    "    if default_args['num_retrieved_documents'] is None:\n",
    "        raise ValueError(\"'num_retrieved_documents' must be specified.\")\n",
    "    if default_args['num_retrieved_documents'] <= 0:\n",
    "        raise ValueError(\"'num_retrieved_documents' must be a positive integer.\")\n",
    "    if default_args['gold_position'] is not None:\n",
    "        if (default_args['gold_position'] < 0 or \n",
    "            default_args['gold_position'] >= default_args['num_retrieved_documents']):\n",
    "            raise ValueError(\"'gold_position' must be within the range of 'num_retrieved_documents'.\")\n",
    "\n",
    "    return DotDict(**default_args)\n",
    "\n",
    "\n",
    "def load_corpus(\n",
    "    args: argparse.Namespace\n",
    ") -> Tuple[List[Dict], Optional[Dict[int, int]]]:\n",
    "    \n",
    "    # Corpus with documents from Contriever\n",
    "    corpus, full_to_subset_idx_map = read_test_corpus_with_random_and_contriever()\n",
    "\n",
    "    return corpus, full_to_subset_idx_map\n",
    "\n",
    "def load_search_results(args: argparse.Namespace) -> List[Tuple[List[int], List[float]]]:\n",
    "    # Search results from Contriever\n",
    "    search_results_path = info['nq']['test']['contriever_search_results_path'] \n",
    "\n",
    "    search_results = read_pickle(search_results_path)\n",
    "    return search_results\n",
    "\n",
    "\n",
    "def get_prompt_template(args: argparse.Namespace):\n",
    "    prompt_configuration = args.dataset\n",
    "\n",
    "    if args.use_model_chat_template:\n",
    "        chat_task_template_str = chat_task_templates[args.llm_id]['template']\n",
    "        \n",
    "        task_instruction = task_instructions[prompt_configuration]\n",
    "        if args.use_task_with_proof:\n",
    "            task_instruction = task_instructions['qa_proof'][prompt_configuration]\n",
    "\n",
    "        prompt_template = apply_chat_task_template(chat_task_template_str, task_instruction)\n",
    "    else:\n",
    "        task_template = task_templates[prompt_configuration]\n",
    "\n",
    "        if args.use_task_with_proof:\n",
    "            task_template = task_templates['qa_proof'][prompt_configuration]\n",
    "\n",
    "        prompt_template = task_template.create_prompt_template()\n",
    "\n",
    "    return prompt_template\n",
    "\n",
    "\n",
    "def initialize_dataset_and_loader(\n",
    "    args: argparse.Namespace, \n",
    "    corpus: List[Dict], \n",
    "    full_to_subset_idx_map: Optional[Dict[int, int]], \n",
    "    retriever_search_results: List[Tuple[List[int], List[float]]], \n",
    "    tokenizer: PreTrainedTokenizer\n",
    ") -> DataLoader:\n",
    "    \n",
    "    prompt_template = get_prompt_template(args)\n",
    "    \n",
    "    prompt_ds = PromptDataset(\n",
    "        corpus=corpus, data_path=info[args.dataset]['test']['data_path'], \n",
    "        tokenizer=tokenizer, \n",
    "        max_tokenized_length=args.model_max_length - 2, \n",
    "        search_results=retriever_search_results,\n",
    "        prompt_template=prompt_template,\n",
    "        full_to_subset_idx_map=full_to_subset_idx_map,\n",
    "        do_normalize_query=True, \n",
    "        num_documents_in_context=args.num_retrieved_documents,\n",
    "        gold_position=args.gold_position, # None in these experiments\n",
    "    )\n",
    "        \n",
    "    prompt_dataloader = DataLoader(\n",
    "        prompt_ds,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return prompt_dataloader\n",
    "\n",
    "\n",
    "def print_info(args: argparse.Namespace):\n",
    "    print(\"INFO:\")    \n",
    "    print(f\"DATA: {info[args.dataset]['test']['data_path']}\")\n",
    "    print(f\"USE TEST: {args.use_test}\")\n",
    "    print(f\"MODEL: {args.llm_id}\")\n",
    "    print(f\"MODEL MAX LENGTH: {args.model_max_length}\")\n",
    "    print(f'MAX NEW TOKENS: {args.max_new_tokens}')\n",
    "    print(f\"USE MODEL CHAT TEMPLATE: {args.use_model_chat_template}\")\n",
    "    print(f\"TASK WITH PROOF:\", args.use_task_with_proof)\n",
    "    print(f\"GOLD POSITION: {args.gold_position}\")\n",
    "    print(f\"NUM DOCUMENTS IN CONTEXT: {args.num_retrieved_documents}\")\n",
    "    print(f\"BATCH SIZE: {args.batch_size}\")\n",
    "    print(f\"SAVE EVERY: {args.save_every}\")\n",
    "\n",
    "\n",
    "def extract_generate_answers(\n",
    "    args: argparse.Namespace, \n",
    "    generated_output: List[str]\n",
    ") -> List[str]:\n",
    "    answer_prefix = \"Answer:\"\n",
    "    if args.use_model_chat_template:\n",
    "        #answer_prefix = re.escape(chat_task_templates[args.llm_id]['answer_prefix'])\n",
    "\n",
    "        answer_prefix = re.escape(\"Answer:\") + r\"\\nmodel\"\n",
    "\n",
    "    print(f\"Answer Prefix: {answer_prefix}\")\n",
    "    print(f\"Generated Output: {generated_output}\")\n",
    "\n",
    "    generated_answers = []\n",
    "    for output in generated_output:\n",
    "        matches = list(re.finditer(answer_prefix, output))\n",
    "\n",
    "        print(f\"Have you find matches?: {matches}\")\n",
    "\n",
    "        match_idx = 0\n",
    "\n",
    "        # When using the proof there is a one-shot example that already \n",
    "        # contains the string \"Answer:\". Thus, we should get the second (match_idx=1) match.\n",
    "        if args.use_task_with_proof:\n",
    "            match_idx = 1\n",
    "            if args.use_model_chat_template and answer_prefix != \"Answer:\":\n",
    "                match_idx = 0\n",
    " \n",
    "        answer_end = matches[match_idx].end()\n",
    "        response = output[answer_end:].strip()\n",
    "        generated_answers.append(response)\n",
    "    \n",
    "    return generated_answers\n",
    "\n",
    "\n",
    "def generate_and_save(\n",
    "    args: argparse.Namespace, \n",
    "    llm: LLM, \n",
    "    prompt_dataloader: DataLoader\n",
    "):\n",
    "    # Info from arguments\n",
    "    llm_id = args.llm_id\n",
    "    num_doc = args.num_retrieved_documents\n",
    "    save_every = args.save_every\n",
    "    retriever_str = \"contriever\"\n",
    "    padding_str = f\"_{args.padding_strategy}{args.model_max_length}\" if args.padding_strategy != \"longest\" else \"\" \n",
    "    chat_template_str = \"_template\" if args.use_model_chat_template else \"\"\n",
    "    prompt_type = \"retrieved_proof\" if args.use_task_with_proof else \"retrieved\"\n",
    "\n",
    "    # Create the saving directory\n",
    "    llm_folder = llm_id.split(\"/\")[1] if '/' in llm_id else llm_id\n",
    "    saving_dir = f\"{args.output_dir}/{args.dataset}/{llm_folder}/test/{prompt_type}/{retriever_str}/{num_doc}_doc\"\n",
    "    os.makedirs(saving_dir, exist_ok=True)\n",
    "\n",
    "    all_info = []  \n",
    "    for idx, prompt_batch in enumerate(tqdm(prompt_dataloader)):\n",
    "        prompts = prompt_batch['prompt']\n",
    "        generated_output = llm.generate(\n",
    "            prompts,\n",
    "            padding_strategy=args.padding_strategy, \n",
    "            max_new_tokens=args.max_new_tokens\n",
    "        )\n",
    "\n",
    "        generated_answers = extract_generate_answers(args, generated_output)\n",
    "        prompt_batch['generated_answer'] = generated_answers\n",
    "        all_info.append(prompt_batch)\n",
    "        \n",
    "        if (idx + 1) % save_every == 0 or (idx + 1) == len(prompt_dataloader):\n",
    "            print(f\"Saving at {idx + 1}...\")\n",
    "            file_name = f\"{saving_dir}/numdoc{num_doc}_retr{args.num_retrieved_documents}{padding_str}{chat_template_str}_info_{idx+1}.pkl\"\n",
    "            write_pickle(all_info, file_name)\n",
    "            all_info = []\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parse_arguments()\n",
    "\n",
    "    print(\"Loading LLM...\")\n",
    "    llm_id = args.llm_id\n",
    "    llm = LLM(\n",
    "        llm_id, device, \n",
    "        quantization_bits=args.quantization_bits, \n",
    "        model_max_length=args.model_max_length\n",
    "    )\n",
    "    tokenizer = llm.tokenizer\n",
    "    print(\"LLM loaded\")\n",
    "\n",
    "\n",
    "    print(\"Loading corpus and search results...\")\n",
    "    corpus, full_to_subset_idx_map = load_corpus(args)\n",
    "    retriever_search_results = load_search_results(args)\n",
    "    print(\"Corpus and search results loaded\")\n",
    "\n",
    "\n",
    "    print(\"Loading prompt dataset...\")\n",
    "    prompt_dataloader = initialize_dataset_and_loader(\n",
    "        args, corpus, full_to_subset_idx_map, \n",
    "        retriever_search_results, tokenizer\n",
    "    )\n",
    "    print(\"Prompt dataset loaded\")\n",
    "\n",
    "    print_info(args)\n",
    "    generate_and_save(args, llm, prompt_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    seed_everything(SEED)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "You are given a question and you must respond based on the provided documents. You must always provide an answer.\n",
      "Documents:\n",
      "Document [628506](Title: Nobel Prize in Physics) receive a diploma, a medal and a document confirming the prize amount. Nobel Prize in Physics The Nobel Prize in Physics () is a yearly award given by the Royal Swedish Academy of Sciences for those who have made the most outstanding contributions for mankind in the field of physics. It is one of the five Nobel Prizes established by the will of Alfred Nobel in 1895 and awarded since 1901; the others being the Nobel Prize in Chemistry, Nobel Prize in Literature, Nobel Peace Prize, and Nobel Prize in Physiology or Medicine. The first Nobel Prize in Physics was\n",
      "Document [3546609](Title: E. C. George Sudarshan) had developed the breakthrough. In 2007, Sudarshan told the \"Hindustan Times\", \"The 2005 Nobel prize for Physics was awarded for my work, but I wasn't the one to get it. Each one of the discoveries that this Nobel was given for work based on my research.\" Sudarshan also commented on not being selected for the 1979 Nobel, \"Steven Weinberg, Sheldon Glashow and Abdus Salam built on work I had done as a 26-year-old student. If you give a prize for a building, shouldn’t the fellow who built the first floor be given the prize before those who built the second\n",
      "Document [439756](Title: University of Chicago) Medal, which is rewarded annually to the best economist under the age of 40, has also been awarded to 4 current members of the university faculty. Notable faculty in physics have included the speed of light calculator A. A. Michelson, elementary charge calculator Robert A. Millikan, discoverer of the Compton Effect Arthur H. Compton, the creator of the first nuclear reactor Enrico Fermi, \"the father of the hydrogen bomb\" Edward Teller, \"one of the most brilliant and productive experimental physicists of the twentieth century\" Luis Walter Alvarez, Murray Gell-Mann who introduced the quark, second female Nobel laureate Maria Goeppert-Mayer, the\n",
      "Document [1860765](Title: Tsung-Dao Lee) 1956, with her so-called Wu experiment. Lee was the youngest Nobel laureate after World War II until Malala Yousafzai was awarded the Nobel Peace Prize in 2014. He is the fourth youngest Nobel laureate in history after William L. Bragg (who won the prize at 25 with his father William H. Bragg in 1915), Werner Heisenberg (who won in 1932 also at 30) and Malala Yousafzai (awarded at just 17). Lee and Yang were the first Chinese laureates. Since he became a naturalized American citizen in 1962, Lee is also the youngest American ever to have won a Nobel Prize.\n",
      "Document [2043329](Title: Universology) become the chief proponent of universology today. \"Everything in this universe is part of an uninterrupted sequence of events\" Mohri has said. In 1872 Andrews published \"The Basic Outline of Universology\" which was subtitled \"An introduction to the newly discovered science of the universe, its elementary principles, and the first stages of their development in the special sciences.\" Ilya Romanovich Prigogine (born on January 25, 1917) was a Belgian and American physicist and chemist who was born in Russia and became a Nobel Prize laureate in chemistry. In the book \"Order Out of Chaos: Man's New Dialogue With Nature\", which\n",
      "Question: who got the first nobel prize in physics\n",
      "Answer:\n",
      "\n",
      "model\n",
      "The provided text does not state who received the first Nobel Prize in Physics.  It only states that the Nobel Prize in Physics was established in 1895 and awarded since 1901. \n",
      "\n",
      "[<re.Match object; span=(3379, 3393), match='Answer:\\n\\nmodel'>]\n"
     ]
    }
   ],
   "source": [
    "generated_output=['user\\nYou are given a question and you must respond based on the provided documents. You must always provide an answer.\\nDocuments:\\nDocument [628506](Title: Nobel Prize in Physics) receive a diploma, a medal and a document confirming the prize amount. Nobel Prize in Physics The Nobel Prize in Physics () is a yearly award given by the Royal Swedish Academy of Sciences for those who have made the most outstanding contributions for mankind in the field of physics. It is one of the five Nobel Prizes established by the will of Alfred Nobel in 1895 and awarded since 1901; the others being the Nobel Prize in Chemistry, Nobel Prize in Literature, Nobel Peace Prize, and Nobel Prize in Physiology or Medicine. The first Nobel Prize in Physics was\\nDocument [3546609](Title: E. C. George Sudarshan) had developed the breakthrough. In 2007, Sudarshan told the \"Hindustan Times\", \"The 2005 Nobel prize for Physics was awarded for my work, but I wasn\\'t the one to get it. Each one of the discoveries that this Nobel was given for work based on my research.\" Sudarshan also commented on not being selected for the 1979 Nobel, \"Steven Weinberg, Sheldon Glashow and Abdus Salam built on work I had done as a 26-year-old student. If you give a prize for a building, shouldn’t the fellow who built the first floor be given the prize before those who built the second\\nDocument [439756](Title: University of Chicago) Medal, which is rewarded annually to the best economist under the age of 40, has also been awarded to 4 current members of the university faculty. Notable faculty in physics have included the speed of light calculator A. A. Michelson, elementary charge calculator Robert A. Millikan, discoverer of the Compton Effect Arthur H. Compton, the creator of the first nuclear reactor Enrico Fermi, \"the father of the hydrogen bomb\" Edward Teller, \"one of the most brilliant and productive experimental physicists of the twentieth century\" Luis Walter Alvarez, Murray Gell-Mann who introduced the quark, second female Nobel laureate Maria Goeppert-Mayer, the\\nDocument [1860765](Title: Tsung-Dao Lee) 1956, with her so-called Wu experiment. Lee was the youngest Nobel laureate after World War II until Malala Yousafzai was awarded the Nobel Peace Prize in 2014. He is the fourth youngest Nobel laureate in history after William L. Bragg (who won the prize at 25 with his father William H. Bragg in 1915), Werner Heisenberg (who won in 1932 also at 30) and Malala Yousafzai (awarded at just 17). Lee and Yang were the first Chinese laureates. Since he became a naturalized American citizen in 1962, Lee is also the youngest American ever to have won a Nobel Prize.\\nDocument [2043329](Title: Universology) become the chief proponent of universology today. \"Everything in this universe is part of an uninterrupted sequence of events\" Mohri has said. In 1872 Andrews published \"The Basic Outline of Universology\" which was subtitled \"An introduction to the newly discovered science of the universe, its elementary principles, and the first stages of their development in the special sciences.\" Ilya Romanovich Prigogine (born on January 25, 1917) was a Belgian and American physicist and chemist who was born in Russia and became a Nobel Prize laureate in chemistry. In the book \"Order Out of Chaos: Man\\'s New Dialogue With Nature\", which\\nQuestion: who got the first nobel prize in physics\\nAnswer:\\n\\nmodel\\nThe provided text does not state who received the first Nobel Prize in Physics.  It only states that the Nobel Prize in Physics was established in 1895 and awarded since 1901. \\n']\n",
    "\n",
    "answer_prefix=\"Answer:\\n\\nmodel\\n\"\n",
    "\n",
    "for output in generated_output:\n",
    "        print(output)\n",
    "        matches = list(re.finditer(answer_prefix, output))\n",
    "        print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoConfig, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    ")\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "\n",
    "class BridgeModel:\n",
    "    \"\"\"\n",
    "    Bridge Model for selecting and ranking documents by generating document IDs.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_id: str, \n",
    "        device: str = 'cuda', \n",
    "        model_max_length: int = 512\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.model_max_length = model_max_length\n",
    "\n",
    "        # Initialize the seq2seq model and tokenizer\n",
    "        self.model, self.tokenizer = self._initialize_model_tokenizer(model_id)\n",
    "\n",
    "    def _initialize_model_tokenizer(self, model_id: str) -> Tuple[AutoModelForSeq2SeqLM, AutoTokenizer]:\n",
    "        \"\"\"\n",
    "        Initializes the seq2seq model and tokenizer with the given model ID.\n",
    "        \"\"\"\n",
    "        model_config = AutoConfig.from_pretrained(model_id, trust_remote_code=True)\n",
    "        model_config.max_seq_len = self.model_max_length\n",
    "\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "            model_id,\n",
    "            trust_remote_code=True,\n",
    "            config=model_config,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "        ).to(self.device)\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_id, \n",
    "            model_max_length=self.model_max_length,\n",
    "            padding_side=\"left\",\n",
    "            truncation_side=\"left\"\n",
    "        )\n",
    "        tokenizer.pad_token = tokenizer.eos_token  # Set pad token\n",
    "\n",
    "        return model, tokenizer\n",
    "\n",
    "    def generate(\n",
    "        self, \n",
    "        prompt: str, \n",
    "        max_new_tokens: int = 15\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        Generates the ordered document IDs based on the query and documents.\n",
    "        \"\"\"\n",
    "        # Tokenize input\n",
    "        inputs = self.tokenizer(\n",
    "            prompt, \n",
    "            return_tensors=\"pt\", \n",
    "            max_length=self.model_max_length, \n",
    "            padding=True, \n",
    "            truncation=True\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Generate output\n",
    "        generated_ids = self.model.generate(\n",
    "            **inputs,\n",
    "            do_sample=False,  # Deterministic output\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            repetition_penalty=1.1,\n",
    "            pad_token_id=self.tokenizer.pad_token_id,\n",
    "            eos_token_id=self.tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        # Decode output\n",
    "        return self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0].split()\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    model_id = \"t5-small\"  # Replace with a seq2seq model like T5 or BART\n",
    "    bridge = BridgeModel(model_id=model_id)\n",
    "\n",
    "    output = bridge.generate(prompt)\n",
    "    print(\"Output document IDs:\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
